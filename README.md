# XAI-AV-Misclassifications
Explaining object detection failures in autonomous vehicles using Grad-CAM and SHAP


---

## ğŸ› ï¸ Technologies Used

- ğŸ§  YOLOv11 (Custom Object Detection Model)
- ğŸ” Grad-CAM (Visual Explanations for CNNs)
- ğŸ§® SHAP (SHapley Additive exPlanations)
- ğŸ“Š KITTI Dataset (Autonomous Vehicle Benchmark)
- ğŸ““ Jupyter Notebooks
- ğŸ Python, NumPy, OpenCV, PyTorch, Matplotlib

---

## ğŸš˜ Problem Statement

Modern object detection models in AVs still face challenges with:
- **Misclassifying pedestrians, cyclists, and static objects**
- **Failing in occluded or low-contrast environments**

This project aims to:
- **Detect** and **log misclassifications**
- **Explain** the failure using interpretable visualizations

---

## ğŸ’¡ Key Insights

- **Grad-CAM** shows where the model "looks" before making decisions.
- **SHAP** explains how different image regions impact the final prediction.
- Misclassifications often arise from:
  - Background clutter
  - Object occlusion
  - Lighting conditions

---


