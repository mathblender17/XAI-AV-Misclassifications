{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1bf7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:45:35.224477Z",
     "iopub.status.busy": "2025-04-21T11:45:35.224134Z",
     "iopub.status.idle": "2025-04-21T11:45:35.234070Z",
     "shell.execute_reply": "2025-04-21T11:45:35.232997Z"
    },
    "papermill": {
     "duration": 0.026894,
     "end_time": "2025-04-21T11:45:35.235488",
     "exception": true,
     "start_time": "2025-04-21T11:45:35.208594",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (3055808070.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    <center style=\"border-radius:10px;\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "<center style=\"border-radius:10px;\n",
    "padding: 3rem 2rem;\n",
    "border: 3px solid #F54257;\n",
    "\">\n",
    "<h1 style=\"color:#F54257; \n",
    "font-size:3.0rem;\n",
    "margin:0;\n",
    "\">KITTI Object Detection</h1>\n",
    "<h2 style=\"color:#F54257; \n",
    "font-size:2.0rem;\n",
    "margin-top:1rem;\n",
    "margin-bottom:2.5rem;\n",
    "\">yolov11m | Ultralytics</h2>\n",
    "<a href=\"https://kaggle.com/shreydan\" style=\"color: white;\n",
    "background-color: #F54257;\n",
    "border-radius: 25px;\n",
    "padding: 1rem 1.5rem;\n",
    "text-decoration: none;\n",
    "\">@shreydan</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4efcb5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Imports\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F03A4F;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d981960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:27:00.050750Z",
     "iopub.status.busy": "2025-04-10T03:27:00.050430Z",
     "iopub.status.idle": "2025-04-10T03:27:09.935755Z",
     "shell.execute_reply": "2025-04-10T03:27:09.934720Z",
     "shell.execute_reply.started": "2025-04-10T03:27:00.050713Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbd8fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:27:09.937536Z",
     "iopub.status.busy": "2025-04-10T03:27:09.937178Z",
     "iopub.status.idle": "2025-04-10T03:27:09.943155Z",
     "shell.execute_reply": "2025-04-10T03:27:09.942331Z",
     "shell.execute_reply.started": "2025-04-10T03:27:09.937491Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env WANDB_DISABLED=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77528731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:11:15.655576Z",
     "iopub.status.busy": "2025-04-13T21:11:15.654741Z",
     "iopub.status.idle": "2025-04-13T21:11:16.103856Z",
     "shell.execute_reply": "2025-04-13T21:11:16.103049Z",
     "shell.execute_reply.started": "2025-04-13T21:11:15.655544Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# !pip install --force-reinstall numpy scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97f5c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:34:07.618367Z",
     "iopub.status.busy": "2025-04-13T21:34:07.617794Z",
     "iopub.status.idle": "2025-04-13T21:34:07.627326Z",
     "shell.execute_reply": "2025-04-13T21:34:07.626504Z",
     "shell.execute_reply.started": "2025-04-13T21:34:07.618336Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = Path('/kaggle/input/kitti-dataset')\n",
    "img_path = base_dir / 'data_object_image_2' / 'training' / 'image_2'\n",
    "label_path = Path('/kaggle/input/kitti-dataset-yolo-format/labels')\n",
    "with open('/kaggle/input/kitti-dataset-yolo-format/classes.json','r') as f:\n",
    "    classes = json.load(f)\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782cf03",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Preparing Dataset\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F27B40;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bede07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:27:13.719765Z",
     "iopub.status.busy": "2025-04-10T03:27:13.719484Z",
     "iopub.status.idle": "2025-04-10T03:27:14.206843Z",
     "shell.execute_reply": "2025-04-10T03:27:14.206027Z",
     "shell.execute_reply.started": "2025-04-10T03:27:13.719738Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ims = sorted(list(img_path.glob('*')))\n",
    "labels = sorted(list(label_path.glob('*')))\n",
    "pairs = list(zip(ims,labels))\n",
    "pairs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87f6f8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Preparing File Structure\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F4B343;margin-bottom: 1rem;\"></div>\n",
    "\n",
    "```\n",
    "/kaggle/working\n",
    "    |\n",
    "    -train\n",
    "    |   |\n",
    "    |   -000000.png\n",
    "    |   -000000.txt\n",
    "    |   ...\n",
    "    |\n",
    "    -val\n",
    "      |\n",
    "      -000001.png\n",
    "      -000001.txt\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59f768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:27:14.208336Z",
     "iopub.status.busy": "2025-04-10T03:27:14.208014Z",
     "iopub.status.idle": "2025-04-10T03:27:14.215176Z",
     "shell.execute_reply": "2025-04-10T03:27:14.214528Z",
     "shell.execute_reply.started": "2025-04-10T03:27:14.208307Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(pairs,test_size=0.1,shuffle=True)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b38cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:27:14.216917Z",
     "iopub.status.busy": "2025-04-10T03:27:14.216147Z",
     "iopub.status.idle": "2025-04-10T03:27:14.227763Z",
     "shell.execute_reply": "2025-04-10T03:27:14.227097Z",
     "shell.execute_reply.started": "2025-04-10T03:27:14.216888Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = Path('train').resolve()\n",
    "train_path.mkdir(exist_ok=True)\n",
    "valid_path = Path('valid').resolve()\n",
    "valid_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb92eaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:27:14.228932Z",
     "iopub.status.busy": "2025-04-10T03:27:14.228699Z",
     "iopub.status.idle": "2025-04-10T03:29:30.429569Z",
     "shell.execute_reply": "2025-04-10T03:29:30.428721Z",
     "shell.execute_reply.started": "2025-04-10T03:27:14.228912Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t_img, t_lb in tqdm(train):\n",
    "    im_path = train_path / t_img.name\n",
    "    lb_path = train_path / t_lb.name\n",
    "    shutil.copy(t_img,im_path)\n",
    "    shutil.copy(t_lb,lb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4d037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:29:30.432554Z",
     "iopub.status.busy": "2025-04-10T03:29:30.432290Z",
     "iopub.status.idle": "2025-04-10T03:29:45.063199Z",
     "shell.execute_reply": "2025-04-10T03:29:45.062335Z",
     "shell.execute_reply.started": "2025-04-10T03:29:30.432531Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t_img, t_lb in tqdm(test):\n",
    "    im_path = valid_path / t_img.name\n",
    "    lb_path = valid_path / t_lb.name\n",
    "    shutil.copy(t_img,im_path)\n",
    "    shutil.copy(t_lb,lb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32a7d7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# YAML file for the data\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F4CE45;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d7fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:29:45.073079Z",
     "iopub.status.busy": "2025-04-10T03:29:45.072860Z",
     "iopub.status.idle": "2025-04-10T03:29:46.114256Z",
     "shell.execute_reply": "2025-04-10T03:29:46.113107Z",
     "shell.execute_reply.started": "2025-04-10T03:29:45.073060Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat kitti.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea685baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:29:45.064854Z",
     "iopub.status.busy": "2025-04-10T03:29:45.064412Z",
     "iopub.status.idle": "2025-04-10T03:29:45.071947Z",
     "shell.execute_reply": "2025-04-10T03:29:45.071124Z",
     "shell.execute_reply.started": "2025-04-10T03:29:45.064819Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yaml_file = 'names:\\n'\n",
    "yaml_file += '\\n'.join(f'- {c}' for c in classes)\n",
    "yaml_file += f'\\nnc: {len(classes)}'\n",
    "yaml_file += f'\\ntrain: {str(train_path)}\\nval: {str(valid_path)}'\n",
    "with open('kitti.yaml','w') as f:\n",
    "    f.write(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29df9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F27B40;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a3009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:04:44.692729Z",
     "iopub.status.busy": "2025-04-14T22:04:44.692506Z",
     "iopub.status.idle": "2025-04-14T22:04:44.701662Z",
     "shell.execute_reply": "2025-04-14T22:04:44.700659Z",
     "shell.execute_reply.started": "2025-04-14T22:04:44.692707Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede93c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:29:46.123032Z",
     "iopub.status.busy": "2025-04-10T03:29:46.122773Z",
     "iopub.status.idle": "2025-04-10T03:29:46.663091Z",
     "shell.execute_reply": "2025-04-10T03:29:46.662376Z",
     "shell.execute_reply.started": "2025-04-10T03:29:46.123011Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/kaggle/input/yolov11m-pt/yolo11m.pt')  # Load YOLOv8 Medium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f87aa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Training\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F5E947;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caececd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T03:29:46.664329Z",
     "iopub.status.busy": "2025-04-10T03:29:46.664079Z",
     "iopub.status.idle": "2025-04-10T07:47:23.860287Z",
     "shell.execute_reply": "2025-04-10T07:47:23.859439Z",
     "shell.execute_reply.started": "2025-04-10T03:29:46.664306Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_results = model.train(\n",
    "#     data='/kaggle/working/kitti.yaml', \n",
    "#     epochs=50,\n",
    "#     patience=3,\n",
    "#     mixup=0.1,\n",
    "#     project='yolov11m-kitti',\n",
    "#     device=0\n",
    "# )\n",
    "\n",
    "train_results = model.train(\n",
    "    data='/kaggle/working/kitti.yaml',\n",
    "    epochs=50,\n",
    "    patience=5,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    mixup=0.1,\n",
    "    lr0=0.01,\n",
    "    optimizer='SGD',\n",
    "    close_mosaic=10,\n",
    "    project='yolov11m-kitti',\n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a5930",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Validation\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #E7F549;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5a0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T07:47:23.862140Z",
     "iopub.status.busy": "2025-04-10T07:47:23.861916Z",
     "iopub.status.idle": "2025-04-10T07:47:36.386021Z",
     "shell.execute_reply": "2025-04-10T07:47:36.385060Z",
     "shell.execute_reply.started": "2025-04-10T07:47:23.862120Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_results = model.val()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d52c57",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Results\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #F25F3E;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe04ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:06:04.402974Z",
     "iopub.status.busy": "2025-04-10T08:06:04.402079Z",
     "iopub.status.idle": "2025-04-10T08:06:04.815689Z",
     "shell.execute_reply": "2025-04-10T08:06:04.814867Z",
     "shell.execute_reply.started": "2025-04-10T08:06:04.402939Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(Image.open('/kaggle/working/yolov11m-kitti/train/results.png'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19628d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:06:08.368674Z",
     "iopub.status.busy": "2025-04-10T08:06:08.368083Z",
     "iopub.status.idle": "2025-04-10T08:06:08.427929Z",
     "shell.execute_reply": "2025-04-10T08:06:08.426709Z",
     "shell.execute_reply.started": "2025-04-10T08:06:08.368617Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(Image.open('/kaggle/working/yolov11m-kitti/val/confusion_matrix.png'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8089a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Predictions\n",
    "<div style=\"width:100%;height:0;border-bottom: 3px solid #CEF64B;margin-bottom: 1rem;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407970d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:06:12.632168Z",
     "iopub.status.busy": "2025-04-10T08:06:12.631386Z",
     "iopub.status.idle": "2025-04-10T08:06:13.683576Z",
     "shell.execute_reply": "2025-04-10T08:06:13.682695Z",
     "shell.execute_reply.started": "2025-04-10T08:06:12.632137Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict([test[idx][0] for idx in np.random.randint(0,len(test),(20,))],save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a62b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:06:32.544891Z",
     "iopub.status.busy": "2025-04-10T08:06:32.544558Z",
     "iopub.status.idle": "2025-04-10T08:06:32.549464Z",
     "shell.execute_reply": "2025-04-10T08:06:32.548437Z",
     "shell.execute_reply.started": "2025-04-10T08:06:32.544867Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = list(Path('yolov11m-kitti/predict').glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df8c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:06:40.970237Z",
     "iopub.status.busy": "2025-04-10T08:06:40.969898Z",
     "iopub.status.idle": "2025-04-10T08:06:41.346085Z",
     "shell.execute_reply": "2025-04-10T08:06:41.344634Z",
     "shell.execute_reply.started": "2025-04-10T08:06:40.970209Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    num_images = len(images)\n",
    "    rows = num_images\n",
    "    cols = 1\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 80))\n",
    "    for ax in axes.flat:\n",
    "        ax.axis('off')\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_images(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70b851",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7eff1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-10T07:47:37.519943Z",
     "iopub.status.idle": "2025-04-10T07:47:37.520352Z",
     "shell.execute_reply": "2025-04-10T07:47:37.520159Z",
     "shell.execute_reply.started": "2025-04-10T07:47:37.520138Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/working/yolov11m-kitti/train/weights/best.pt /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30c098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:08:53.691445Z",
     "iopub.status.busy": "2025-04-10T08:08:53.690626Z",
     "iopub.status.idle": "2025-04-10T08:08:58.925142Z",
     "shell.execute_reply": "2025-04-10T08:08:58.924065Z",
     "shell.execute_reply.started": "2025-04-10T08:08:53.691402Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip -r results.zip yolov11m-kitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99582e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:09:48.712699Z",
     "iopub.status.busy": "2025-04-10T08:09:48.711978Z",
     "iopub.status.idle": "2025-04-10T08:09:49.778806Z",
     "shell.execute_reply": "2025-04-10T08:09:49.777694Z",
     "shell.execute_reply.started": "2025-04-10T08:09:48.712665Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf yolov11m-kitti wandb train.cache valid.cache yolov11m.pt train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b6c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T12:54:40.987034Z",
     "iopub.status.busy": "2025-04-13T12:54:40.986238Z",
     "iopub.status.idle": "2025-04-13T12:54:40.991364Z",
     "shell.execute_reply": "2025-04-13T12:54:40.990496Z",
     "shell.execute_reply.started": "2025-04-13T12:54:40.987005Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0153247d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Dataset kaam start Collecting 10 missclassified images per class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee920d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T11:53:14.325388Z",
     "iopub.status.busy": "2025-04-14T11:53:14.324544Z",
     "iopub.status.idle": "2025-04-14T11:53:14.473733Z",
     "shell.execute_reply": "2025-04-14T11:53:14.473024Z",
     "shell.execute_reply.started": "2025-04-14T11:53:14.325360Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "base_dir = Path('/kaggle/input/kitti-dataset')\n",
    "img_path = base_dir / 'data_object_image_3' / 'testing' / 'image_3'\n",
    "label_path = Path('/kaggle/input/kitti-dataset-yolo-format/labels')\n",
    "\n",
    "with open('/kaggle/input/kitti-dataset-yolo-format/classes.json','r') as f:\n",
    "    classes = json.load(f)\n",
    "\n",
    "ims = sorted(list(img_path.glob('*')))\n",
    "labels = sorted(list(label_path.glob('*')))\n",
    "pairs = list(zip(ims, labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdaf9bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### check loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e60c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T11:53:14.475780Z",
     "iopub.status.busy": "2025-04-14T11:53:14.475441Z",
     "iopub.status.idle": "2025-04-14T11:53:14.481189Z",
     "shell.execute_reply": "2025-04-14T11:53:14.480277Z",
     "shell.execute_reply.started": "2025-04-14T11:53:14.475750Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(ims[:5])  # Print the first 5 image file paths\n",
    "print(labels[:5])  # Print the first 5 label file paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc922e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T11:53:14.482531Z",
     "iopub.status.busy": "2025-04-14T11:53:14.482205Z",
     "iopub.status.idle": "2025-04-14T11:53:14.492436Z",
     "shell.execute_reply": "2025-04-14T11:53:14.491666Z",
     "shell.execute_reply.started": "2025-04-14T11:53:14.482508Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pairs[:5])  # Print the first 5 paired image-label paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c28769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T11:53:14.494466Z",
     "iopub.status.busy": "2025-04-14T11:53:14.494180Z",
     "iopub.status.idle": "2025-04-14T11:53:14.501926Z",
     "shell.execute_reply": "2025-04-14T11:53:14.501089Z",
     "shell.execute_reply.started": "2025-04-14T11:53:14.494446Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7f36d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21777f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:18:59.268763Z",
     "iopub.status.busy": "2025-04-14T22:18:59.268170Z",
     "iopub.status.idle": "2025-04-14T22:19:10.161923Z",
     "shell.execute_reply": "2025-04-14T22:19:10.160820Z",
     "shell.execute_reply.started": "2025-04-14T22:18:59.268733Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3554fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:19:10.163971Z",
     "iopub.status.busy": "2025-04-14T22:19:10.163671Z",
     "iopub.status.idle": "2025-04-14T22:19:15.478839Z",
     "shell.execute_reply": "2025-04-14T22:19:15.477635Z",
     "shell.execute_reply.started": "2025-04-14T22:19:10.163940Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model_path = '/kaggle/input/yolo11_trained/pytorch/default/1/yolo11m.pt'\n",
    "model = YOLO(model_path, task='detect')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b154381",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d3372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T14:01:37.433505Z",
     "iopub.status.busy": "2025-04-14T14:01:37.432707Z",
     "iopub.status.idle": "2025-04-14T14:01:37.817670Z",
     "shell.execute_reply": "2025-04-14T14:01:37.816868Z",
     "shell.execute_reply.started": "2025-04-14T14:01:37.433476Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Randomly pick an image from the test dataset\n",
    "image_path = random.choice(ims)\n",
    "\n",
    "# Read and convert the image to RGB\n",
    "image = cv2.imread(str(image_path))\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image_path)  # Inference on the selected image\n",
    "print(\"Hi\")\n",
    "# Extract predictions from results\n",
    "predictions = results[0].boxes  # Access the boxes (predictions)\n",
    "\n",
    "# Print predictions (bounding boxes, class ids, etc.)\n",
    "print(predictions)\n",
    "\n",
    "# Optionally, visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image_rgb)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f67615",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### visual bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0a91f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T14:01:43.880290Z",
     "iopub.status.busy": "2025-04-14T14:01:43.879944Z",
     "iopub.status.idle": "2025-04-14T14:01:43.892040Z",
     "shell.execute_reply": "2025-04-14T14:01:43.891091Z",
     "shell.execute_reply.started": "2025-04-14T14:01:43.880261Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the predicted bounding boxes, class IDs, and confidence scores\n",
    "boxes = results[0].boxes.xyxy  # bounding box coordinates in xyxy format\n",
    "class_ids = results[0].boxes.cls  # class IDs of detected objects\n",
    "confidences = results[0].boxes.conf  # confidence scores of detections\n",
    "\n",
    "# Print the results\n",
    "print(\"Bounding Boxes:\", boxes)\n",
    "print(\"Class IDs:\", class_ids)\n",
    "print(\"Confidence Scores:\", confidences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a7827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T14:01:49.133521Z",
     "iopub.status.busy": "2025-04-14T14:01:49.132790Z",
     "iopub.status.idle": "2025-04-14T14:01:49.137998Z",
     "shell.execute_reply": "2025-04-14T14:01:49.136993Z",
     "shell.execute_reply.started": "2025-04-14T14:01:49.133493Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = {'Car': 0, 'Pedestrian': 1, 'Van': 2, 'Cyclist': 3, 'Truck': 4, 'Misc': 5, 'Tram': 6, 'Person_sitting': 7}\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273c452",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### directoy creation for misclassiifed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9b017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:19:59.596757Z",
     "iopub.status.busy": "2025-04-14T22:19:59.595938Z",
     "iopub.status.idle": "2025-04-14T22:19:59.600802Z",
     "shell.execute_reply": "2025-04-14T22:19:59.599894Z",
     "shell.execute_reply.started": "2025-04-14T22:19:59.596728Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_to_label = {\n",
    "    '0': 'Car',\n",
    "    '1': 'Pedestrian',\n",
    "    '2': 'Van',\n",
    "    '3': 'Cyclist',\n",
    "    '4': 'Truck',\n",
    "    '5': 'Misc',\n",
    "    '6': 'Tram',\n",
    "    '7': 'Person_sitting'\n",
    "}\n",
    "#class_mapping= {v: k for k, v in class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae767d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T14:02:00.526175Z",
     "iopub.status.busy": "2025-04-14T14:02:00.525813Z",
     "iopub.status.idle": "2025-04-14T14:02:00.531204Z",
     "shell.execute_reply": "2025-04-14T14:02:00.530072Z",
     "shell.execute_reply.started": "2025-04-14T14:02:00.526137Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(\"Class Mapping: \", class_mapping)\n",
    "print(\"index_to_label: \", index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b55686",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95329b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Agin created the misclassified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d7eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:18:41.091764Z",
     "iopub.status.busy": "2025-04-14T22:18:41.090956Z",
     "iopub.status.idle": "2025-04-14T22:18:41.097139Z",
     "shell.execute_reply": "2025-04-14T22:18:41.096186Z",
     "shell.execute_reply.started": "2025-04-14T22:18:41.091734Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the misclassified directory\n",
    "misclassified_dir = Path('/kaggle/working/misclassified')\n",
    "\n",
    "# Check if the directory exists\n",
    "if misclassified_dir.exists():\n",
    "    # Remove the entire misclassified directory and its contents\n",
    "    shutil.rmtree(misclassified_dir)\n",
    "    print(\"Old misclassified dataset has been cleaned.\")\n",
    "\n",
    "# Recreate the misclassified directory\n",
    "misclassified_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Misclassified dataset folder has been recreated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cd375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:18:42.668680Z",
     "iopub.status.busy": "2025-04-14T22:18:42.668054Z",
     "iopub.status.idle": "2025-04-14T22:18:42.674108Z",
     "shell.execute_reply": "2025-04-14T22:18:42.673276Z",
     "shell.execute_reply.started": "2025-04-14T22:18:42.668652Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Path to the misclassified directory\n",
    "misclassified_dir = Path('/kaggle/working/misclassified')\n",
    "\n",
    "# Create 'images' and 'labels' directories inside 'misclassified'\n",
    "images_dir = misclassified_dir / 'images'\n",
    "labels_dir = misclassified_dir / 'labels'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Subdirectories 'images' and 'labels' have been created inside 'misclassified'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc649b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:18:46.852322Z",
     "iopub.status.busy": "2025-04-14T22:18:46.851965Z",
     "iopub.status.idle": "2025-04-14T22:18:46.858240Z",
     "shell.execute_reply": "2025-04-14T22:18:46.857260Z",
     "shell.execute_reply.started": "2025-04-14T22:18:46.852294Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the 'labels' directory inside 'misclassified'\n",
    "actual_dir = labels_dir / 'actual'\n",
    "predicted_dir = labels_dir / 'predicted'\n",
    "\n",
    "# Create the 'actual' and 'predicted' directories if they don't exist\n",
    "actual_dir.mkdir(parents=True, exist_ok=True)\n",
    "predicted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Subdirectories 'actual' and 'predicted' have been created inside 'labels'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58075ea6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# checking and adding values in misclassified dataset - DEMO Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149d15b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:19:15.481018Z",
     "iopub.status.busy": "2025-04-14T22:19:15.480310Z",
     "iopub.status.idle": "2025-04-14T22:19:15.634867Z",
     "shell.execute_reply": "2025-04-14T22:19:15.634005Z",
     "shell.execute_reply.started": "2025-04-14T22:19:15.480982Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLOv11 model (update path if needed)\n",
    "model_path = '/kaggle/input/yolo11_trained/pytorch/default/1/yolo11m.pt'  # or wherever your best model is saved\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(\"✅ Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8f354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:19:43.843894Z",
     "iopub.status.busy": "2025-04-14T22:19:43.843564Z",
     "iopub.status.idle": "2025-04-14T22:19:49.382622Z",
     "shell.execute_reply": "2025-04-14T22:19:49.381790Z",
     "shell.execute_reply.started": "2025-04-14T22:19:43.843867Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Define path to your validation images\n",
    "val_images_path = Path('/kaggle/input/kitti-dataset/data_object_image_3/testing/image_3')  # change if needed\n",
    "\n",
    "# Get list of image files\n",
    "val_image_files = list(val_images_path.glob('*.jpg')) + list(val_images_path.glob('*.png'))\n",
    "\n",
    "# Pick 5 random images\n",
    "sample_images = random.sample(val_image_files, 5)\n",
    "\n",
    "# Run inference and display predictions\n",
    "for image_path in sample_images:\n",
    "    # Run YOLO prediction\n",
    "    results = model(image_path)\n",
    "\n",
    "    # Plot image with prediction\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predictions for: {image_path.name}\")\n",
    "    results[0].plot(show=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241d928",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### comparing the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b39d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:20:07.265637Z",
     "iopub.status.busy": "2025-04-14T22:20:07.265007Z",
     "iopub.status.idle": "2025-04-14T22:20:07.596410Z",
     "shell.execute_reply": "2025-04-14T22:20:07.595503Z",
     "shell.execute_reply.started": "2025-04-14T22:20:07.265607Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Assuming index_to_label is already defined\n",
    "# Example: index_to_label = {0: 'Car', 1: 'Pedestrian', ...}\n",
    "\n",
    "# Paths\n",
    "val_images_path = Path('/kaggle/input/kitti-dataset/data_object_image_3/testing/image_3')\n",
    "val_labels_path = Path('/kaggle/input/kitti-dataset-yolo-format/labels')\n",
    "\n",
    "# Get list of images\n",
    "val_image_files = list(val_images_path.glob('*.jpg')) + list(val_images_path.glob('*.png'))\n",
    "sample_images = random.sample(val_image_files, 5)\n",
    "\n",
    "# Process each image\n",
    "for image_path in sample_images:\n",
    "    label_path = val_labels_path / (image_path.stem + '.txt')\n",
    "\n",
    "    print(f\"\\n🔍 Image: {image_path.name}\")\n",
    "\n",
    "    # Load actual labels from label file\n",
    "    actual_classes = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                class_index = int(line.split()[0])\n",
    "                actual_classes.append(index_to_label.get(class_index, f\"Unknown-{class_index}\"))\n",
    "    else:\n",
    "        actual_classes.append(\"Label file missing\")\n",
    "\n",
    "    # Run prediction\n",
    "    results = model(image_path)\n",
    "    predicted_classes = []\n",
    "    if results and results[0].boxes is not None:\n",
    "        predicted_indices = results[0].boxes.cls.int().tolist()\n",
    "        predicted_classes = [index_to_label.get(i, f\"Unknown-{i}\") for i in predicted_indices]\n",
    "    else:\n",
    "        predicted_classes.append(\"No predictions\")\n",
    "\n",
    "    print(f\"✅ Actual Labels   : {actual_classes}\")\n",
    "    print(f\"🔮 Predicted Labels: {predicted_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722a93e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## partial/ complete / multiple Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db97d48",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Assuming index_to_label is already defined\n",
    "# Example: index_to_label = {0: 'Car', 1: 'Pedestrian', ...}\n",
    "\n",
    "# Paths\n",
    "val_images_path = Path('/kaggle/input/kitti-dataset/data_object_image_3/testing/image_3')\n",
    "val_labels_path = Path('/kaggle/input/kitti-dataset-yolo-format/labels')\n",
    "\n",
    "# Get list of images\n",
    "val_image_files = list(val_images_path.glob('*.jpg')) + list(val_images_path.glob('*.png'))\n",
    "sample_images = random.sample(val_image_files, 5)\n",
    "\n",
    "# Process each image\n",
    "for image_path in sample_images:\n",
    "    label_path = val_labels_path / (image_path.stem + '.txt')\n",
    "\n",
    "    print(f\"\\n🔍 Image: {image_path.name}\")\n",
    "\n",
    "    # Load actual labels from label file\n",
    "    actual_classes = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                class_index = int(line.split()[0])\n",
    "                actual_classes.append(index_to_label.get(class_index, f\"Unknown-{class_index}\"))\n",
    "    else:\n",
    "        actual_classes.append(\"Label file missing\")\n",
    "\n",
    "    # Run prediction\n",
    "    results = model(image_path)\n",
    "    predicted_classes = []\n",
    "    if results and results[0].boxes is not None:\n",
    "        predicted_indices = results[0].boxes.cls.int().tolist()\n",
    "        predicted_classes = [index_to_label.get(i, f\"Unknown-{i}\") for i in predicted_indices]\n",
    "    else:\n",
    "        predicted_classes.append(\"No predictions\")\n",
    "\n",
    "    print(f\"✅ Actual Labels   : {actual_classes}\")\n",
    "    print(f\"🔮 Predicted Labels: {predicted_classes}\")\n",
    "\n",
    "    # Check for partial accuracy (if at least one predicted label matches)\n",
    "    correct_predictions = []\n",
    "    incorrect_predictions = []\n",
    "\n",
    "    for predicted in predicted_classes:\n",
    "        if predicted in actual_classes:\n",
    "            correct_predictions.append(predicted)\n",
    "        else:\n",
    "            incorrect_predictions.append(predicted)\n",
    "\n",
    "    print(f\"✅ Correct Predictions: {correct_predictions}\")\n",
    "    print(f\"❌ Incorrect Predictions: {incorrect_predictions}\")\n",
    "\n",
    "    # Check for overall accuracy (if all predicted labels match)\n",
    "    if len(predicted_classes) == len(actual_classes) and all(p in actual_classes for p in predicted_classes):\n",
    "        print(\"✅ Overall Accuracy: Correct (all labels match)\")\n",
    "    else:\n",
    "        print(\"❌ Overall Accuracy: Incorrect (not all labels match)\")\n",
    "\n",
    "    # Check for multiple matching labels\n",
    "    matched_count = 0\n",
    "    for predicted in predicted_classes:\n",
    "        if predicted in actual_classes:\n",
    "            matched_count += 1\n",
    "\n",
    "    print(f\"🔮 Multiple Matching Labels: {matched_count} out of {len(predicted_classes)} matched labels.\")\n",
    "    \n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c2b0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### filling the misclassification dataset - with 10 img each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd6bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T13:56:05.592745Z",
     "iopub.status.busy": "2025-04-14T13:56:05.592107Z",
     "iopub.status.idle": "2025-04-14T13:56:09.503580Z",
     "shell.execute_reply": "2025-04-14T13:56:09.502727Z",
     "shell.execute_reply.started": "2025-04-14T13:56:05.592715Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "val_images_path = Path('/kaggle/input/kitti-dataset/data_object_image_3/testing/image_3')\n",
    "val_labels_path = Path('/kaggle/input/kitti-dataset-yolo-format/labels')\n",
    "\n",
    "# Output folders\n",
    "base_dir = Path('/kaggle/working/misclassified')\n",
    "img_save_dir = base_dir/ 'images'\n",
    "actual_label_dir = base_dir / 'labels' / 'actual'\n",
    "pred_label_dir = base_dir / 'labels' / 'predicted'\n",
    "\n",
    "# Create folders\n",
    "img_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "actual_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "pred_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Index mapping\n",
    "index_to_label = {\n",
    "    0: 'Car',\n",
    "    1: 'Pedestrian',\n",
    "    2: 'Van',\n",
    "    3: 'Cyclist',\n",
    "    4: 'Truck',\n",
    "    5: 'Misc',\n",
    "    6: 'Tram',\n",
    "    7: 'Person_sitting'\n",
    "}\n",
    "\n",
    "# Load 250 images\n",
    "val_image_files = sorted(list(val_images_path.glob('*.png')) + list(val_images_path.glob('*.jpg')))[:250]\n",
    "\n",
    "misclassified_count = 0\n",
    "misclassified_limit = 100\n",
    "image_counter = 1\n",
    "\n",
    "for image_path in val_image_files:\n",
    "    if misclassified_count >= misclassified_limit:\n",
    "        break\n",
    "\n",
    "    label_path = val_labels_path / (image_path.stem + '.txt')\n",
    "\n",
    "    # Load actual classes\n",
    "    actual_classes = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                class_index = int(line.split()[0])\n",
    "                actual_classes.append(index_to_label.get(class_index, f\"Unknown-{class_index}\"))\n",
    "    else:\n",
    "        actual_classes.append(\"Label file missing\")\n",
    "\n",
    "    # Run prediction\n",
    "    results = model(image_path)\n",
    "    predicted_classes = []\n",
    "    if results and results[0].boxes is not None:\n",
    "        predicted_indices = results[0].boxes.cls.int().tolist()\n",
    "        predicted_classes = [index_to_label.get(i, f\"Unknown-{i}\") for i in predicted_indices]\n",
    "    else:\n",
    "        predicted_classes.append(\"No predictions\")\n",
    "\n",
    "    # Compare sets for misclassification\n",
    "    if set(actual_classes) != set(predicted_classes):\n",
    "        misclassified_count += 1\n",
    "        save_name = f\"misclassified_image_{image_counter}.png\"\n",
    "        shutil.copy(image_path, img_save_dir / save_name)\n",
    "\n",
    "        # Save actual labels\n",
    "        with open(actual_label_dir / f\"misclassified_image_{image_counter}.txt\", 'w') as f:\n",
    "            f.write(\", \".join(actual_classes))\n",
    "\n",
    "        # Save predicted labels\n",
    "        with open(pred_label_dir / f\"misclassified_image_{image_counter}.txt\", 'w') as f:\n",
    "            f.write(\", \".join(predicted_classes))\n",
    "\n",
    "        image_counter += 1\n",
    "\n",
    "print(f\"✅ Saved {misclassified_count} misclassified images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7054a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T13:56:21.430480Z",
     "iopub.status.busy": "2025-04-14T13:56:21.430117Z",
     "iopub.status.idle": "2025-04-14T13:56:21.437061Z",
     "shell.execute_reply": "2025-04-14T13:56:21.436206Z",
     "shell.execute_reply.started": "2025-04-14T13:56:21.430453Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Path to your misclassified image folder\n",
    "img_path = Path('/kaggle/working/misclassified/images')\n",
    "\n",
    "# Count .png and .jpg images\n",
    "image_files = list(img_path.glob('misclassified_image_*.png')) + list(img_path.glob('misclassified_image_*.jpg'))\n",
    "print(f\"📸 Total misclassified images found: {len(image_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715cbe92",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-14T11:53:24.944540Z",
     "iopub.status.idle": "2025-04-14T11:53:24.944948Z",
     "shell.execute_reply": "2025-04-14T11:53:24.944758Z",
     "shell.execute_reply.started": "2025-04-14T11:53:24.944736Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the entire folder\n",
    "shutil.make_archive(\"misclassified_dataset\", 'zip', \"misclassified\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0588b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Misclassification dataset complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9b499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:16:30.642947Z",
     "iopub.status.busy": "2025-04-14T12:16:30.642587Z",
     "iopub.status.idle": "2025-04-14T12:16:30.653394Z",
     "shell.execute_reply": "2025-04-14T12:16:30.652465Z",
     "shell.execute_reply.started": "2025-04-14T12:16:30.642917Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "image_dir = Path('./misclassified/images')\n",
    "actual_label_dir = Path('./misclassified/labels/actual')\n",
    "predicted_label_dir = Path('./misclassified/labels/predicted')\n",
    "\n",
    "# Get list of all misclassified image files\n",
    "all_images = list(image_dir.glob('misclassified_image_*.png'))\n",
    "\n",
    "# Choose 5 random images\n",
    "sample_images = random.sample(all_images, 5)\n",
    "\n",
    "# Display comparisons\n",
    "for image_path in sample_images:\n",
    "    image_name = image_path.stem  # e.g., \"misclassified_image_12\"\n",
    "\n",
    "    actual_label_path = actual_label_dir / f\"{image_name}.txt\"\n",
    "    predicted_label_path = predicted_label_dir / f\"{image_name}.txt\"\n",
    "\n",
    "    # Read labels\n",
    "    actual_labels = actual_label_path.read_text().strip().splitlines() if actual_label_path.exists() else [\"Missing\"]\n",
    "    predicted_labels = predicted_label_path.read_text().strip().splitlines() if predicted_label_path.exists() else [\"Missing\"]\n",
    "\n",
    "    print(f\"🖼️ Image: {image_path.name}\")\n",
    "    print(f\"✅ Actual Labels   : {actual_labels}\")\n",
    "    print(f\"🔮 Predicted Labels: {predicted_labels}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634264ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:16:36.929867Z",
     "iopub.status.busy": "2025-04-14T12:16:36.929077Z",
     "iopub.status.idle": "2025-04-14T12:16:37.823426Z",
     "shell.execute_reply": "2025-04-14T12:16:37.822558Z",
     "shell.execute_reply.started": "2025-04-14T12:16:36.929839Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Paths\n",
    "image_dir = Path('./misclassified/images')\n",
    "actual_label_dir = Path('./misclassified/labels/actual')\n",
    "predicted_label_dir = Path('./misclassified/labels/predicted')\n",
    "\n",
    "# Get list of all misclassified images\n",
    "all_images = list(image_dir.glob('misclassified_image_*.png'))\n",
    "\n",
    "# Pick 5 random samples\n",
    "sample_images = random.sample(all_images, 5)\n",
    "\n",
    "# Plot each image with actual & predicted labels\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, image_path in enumerate(sample_images):\n",
    "    image_name = image_path.stem  # misclassified_image_{i}\n",
    "    \n",
    "    # Read actual and predicted labels\n",
    "    actual_label_path = actual_label_dir / f\"{image_name}.txt\"\n",
    "    predicted_label_path = predicted_label_dir / f\"{image_name}.txt\"\n",
    "\n",
    "    actual_labels = actual_label_path.read_text().strip().splitlines() if actual_label_path.exists() else [\"Missing\"]\n",
    "    predicted_labels = predicted_label_path.read_text().strip().splitlines() if predicted_label_path.exists() else [\"Missing\"]\n",
    "\n",
    "    # Load and convert image (OpenCV loads as BGR)\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot\n",
    "    plt.subplot(2, 3, idx + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{image_name}\\nActual: {actual_labels}\\nPred: {predicted_labels}\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf680ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:16:50.824637Z",
     "iopub.status.busy": "2025-04-14T12:16:50.824281Z",
     "iopub.status.idle": "2025-04-14T12:16:50.841745Z",
     "shell.execute_reply": "2025-04-14T12:16:50.840803Z",
     "shell.execute_reply.started": "2025-04-14T12:16:50.824614Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "actual_dir = Path('./misclassified/labels/actual')\n",
    "predicted_dir = Path('./misclassified/labels/predicted')\n",
    "\n",
    "complete = 0\n",
    "partial = 0\n",
    "multiple = 0\n",
    "\n",
    "total = 0\n",
    "\n",
    "for actual_file in actual_dir.glob('*.txt'):\n",
    "    name = actual_file.stem\n",
    "    predicted_file = predicted_dir / f\"{name}.txt\"\n",
    "\n",
    "    if not predicted_file.exists():\n",
    "        continue\n",
    "\n",
    "    actual_labels = actual_file.read_text().strip().splitlines()\n",
    "    predicted_labels = predicted_file.read_text().strip().splitlines()\n",
    "\n",
    "    total += 1\n",
    "\n",
    "    if set(actual_labels) == set(predicted_labels):\n",
    "        complete += 1\n",
    "    elif any(label in actual_labels for label in predicted_labels):\n",
    "        partial += 1\n",
    "    else:\n",
    "        multiple += 1\n",
    "\n",
    "# 🔢 Print Results\n",
    "print(f\"Total Misclassified Images Analyzed: {total}\")\n",
    "print(f\"✅ Complete Matches     : {complete}\")\n",
    "print(f\"🟡 Partial Matches      : {partial}\")\n",
    "print(f\"❌ Multiple Mismatches  : {multiple}\")\n",
    "\n",
    "# Optional: Accuracy %\n",
    "print(\"\\n📊 Accuracy Breakdown:\")\n",
    "print(f\"Complete Accuracy : {100 * complete / total:.2f}%\")\n",
    "print(f\"Partial Accuracy  : {100 * partial / total:.2f}%\")\n",
    "print(f\"Multiple Accuracy : {100 * multiple / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512aa06c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Now We'l Start Grad-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f383b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Image Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33f816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T07:17:46.740849Z",
     "iopub.status.busy": "2025-04-21T07:17:46.740272Z",
     "iopub.status.idle": "2025-04-21T07:17:56.515310Z",
     "shell.execute_reply": "2025-04-21T07:17:56.514400Z",
     "shell.execute_reply.started": "2025-04-21T07:17:46.740821Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec52d8",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-04-21T10:17:07.998698Z",
     "iopub.status.busy": "2025-04-21T10:17:07.998079Z",
     "iopub.status.idle": "2025-04-21T10:17:10.650123Z",
     "shell.execute_reply": "2025-04-21T10:17:10.649275Z",
     "shell.execute_reply.started": "2025-04-21T10:17:07.998667Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load the YOLOv11 model\n",
    "model = YOLO(\"/kaggle/input/yolov11m-pt/yolo11m.pt\")\n",
    "# Predict on a sample image\n",
    "image_path =   \"/kaggle/input/kitti-dataset/data_object_image_2/testing/image_2/000002.png\" \n",
    "# image_path = \"/kaggle/input/kitti-dataset/data_object_image_3/testing/image_3/000004.png\"\n",
    "results = model.predict(source=image_path, conf=0.25, save=False)\n",
    "# Display predictions inline (optional)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64c2f8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Acessing Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf95cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T08:07:07.053402Z",
     "iopub.status.busy": "2025-04-21T08:07:07.053050Z",
     "iopub.status.idle": "2025-04-21T08:07:07.066967Z",
     "shell.execute_reply": "2025-04-21T08:07:07.066162Z",
     "shell.execute_reply.started": "2025-04-21T08:07:07.053373Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the first result\n",
    "result = results[0]\n",
    "\n",
    "# Accessing the bounding boxes (contains bounding box coordinates in x1, y1, x2, y2 format)\n",
    "print(\"**& Boxes (x1, y1, x2, y2 format):\", result.boxes)\n",
    "\n",
    "# Accessing the class IDs (numeric)\n",
    "#print(\"**& Class IDs (numeric):\", result.cls)\n",
    "\n",
    "# Accessing confidence scores\n",
    "#print(\"**& Confidence Scores:\", result.conf)\n",
    "\n",
    "# Accessing class names (mapping numeric class IDs to human-readable class names)\n",
    "print(\"**& Class Names:\", result.names)\n",
    "\n",
    "# Accessing the original image\n",
    "print(\"**& Original Image:\", result.orig_img)\n",
    "\n",
    "# Accessing the original image shape\n",
    "print(\"**& Original Image Shape:\", result.orig_shape)\n",
    "\n",
    "# Speed metrics (time taken for preprocessing, inference, and postprocessing)\n",
    "print(\"**& Speed metrics:\", result.speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eef664",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Acessing Names from results - CLASSS ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624004cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T08:30:44.671508Z",
     "iopub.status.busy": "2025-04-21T08:30:44.670883Z",
     "iopub.status.idle": "2025-04-21T08:30:44.677538Z",
     "shell.execute_reply": "2025-04-21T08:30:44.676727Z",
     "shell.execute_reply.started": "2025-04-21T08:30:44.671482Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the first result\n",
    "result = results[0]\n",
    "\n",
    "# Accessing the class names dictionary\n",
    "class_names = result.names\n",
    "\n",
    "# Example: If you want to print the class name corresponding to a class ID\n",
    "for class_id in result.boxes.cls:\n",
    "    class_name = class_names[int(class_id)]  # Convert class_id to a string using the 'names' dictionary\n",
    "    print(f\"Class ID: {class_id} corresponds to Class Name: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f32a2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Acessing prob from results - CONFIDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00a59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T08:34:26.075103Z",
     "iopub.status.busy": "2025-04-21T08:34:26.074766Z",
     "iopub.status.idle": "2025-04-21T08:34:26.081501Z",
     "shell.execute_reply": "2025-04-21T08:34:26.080518Z",
     "shell.execute_reply.started": "2025-04-21T08:34:26.075080Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the first result\n",
    "result = results[0]\n",
    "\n",
    "# Access confidence scores\n",
    "confidence_scores = result.boxes.conf\n",
    "\n",
    "# Access class IDs\n",
    "class_ids = result.boxes.cls\n",
    "\n",
    "# Display the confidence score and class ID for each detection\n",
    "for i, (score, cls) in enumerate(zip(confidence_scores, class_ids)):\n",
    "    print(f\"Detection {i} - Confidence Score: {score:.4f}, Class ID: {cls.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbfaba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### which car to which probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64b9ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:18:08.778167Z",
     "iopub.status.busy": "2025-04-21T10:18:08.777804Z",
     "iopub.status.idle": "2025-04-21T10:18:08.787821Z",
     "shell.execute_reply": "2025-04-21T10:18:08.786804Z",
     "shell.execute_reply.started": "2025-04-21T10:18:08.778136Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = results[0]\n",
    "\n",
    "# Get everything\n",
    "boxes = result.boxes\n",
    "confidences = boxes.conf\n",
    "class_ids = boxes.cls\n",
    "coords = boxes.xyxy  # or boxes.xywh if you prefer center format\n",
    "\n",
    "# Map class IDs to class names\n",
    "class_names = result.names\n",
    "\n",
    "# Print detailed info\n",
    "for i, (score, cls, coord) in enumerate(zip(confidences, class_ids, coords)):\n",
    "    class_name = class_names[int(cls)]\n",
    "    x1, y1, x2, y2 = coord.tolist()\n",
    "    print(f\"Detection {i}:\")\n",
    "    print(f\"  Class       : {class_name} (ID {int(cls)})\")\n",
    "    print(f\"  Confidence  : {score:.4f}\")\n",
    "    print(f\"  BBox [xyxy] : ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83a0fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:18:44.917576Z",
     "iopub.status.busy": "2025-04-21T10:18:44.916802Z",
     "iopub.status.idle": "2025-04-21T10:18:45.097915Z",
     "shell.execute_reply": "2025-04-21T10:18:45.097056Z",
     "shell.execute_reply.started": "2025-04-21T10:18:44.917536Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "# Load original image\n",
    "img = Image.open(result.path).convert(\"RGB\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Try to use a nicer font, fall back to default\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=14)\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "# Draw each detection with bounding box, class name, score, and detection index\n",
    "for i, (score, cls, coord) in enumerate(zip(confidences, class_ids, coords)):\n",
    "    x1, y1, x2, y2 = coord.tolist()\n",
    "    class_name = class_names[int(cls)]\n",
    "    label = f\"[{i}] {class_name} {score:.2f}\"\n",
    "\n",
    "    draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "    draw.text((x1, max(0, y1 - 15)), label, fill=\"yellow\", font=font)\n",
    "\n",
    "# Display inline in notebook\n",
    "display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf25ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:15:30.150296Z",
     "iopub.status.busy": "2025-04-21T10:15:30.149721Z",
     "iopub.status.idle": "2025-04-21T10:15:48.998175Z",
     "shell.execute_reply": "2025-04-21T10:15:48.997162Z",
     "shell.execute_reply.started": "2025-04-21T10:15:30.150268Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q grad-cam\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69bcd76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:15:49.000034Z",
     "iopub.status.busy": "2025-04-21T10:15:48.999771Z",
     "iopub.status.idle": "2025-04-21T10:15:57.970075Z",
     "shell.execute_reply": "2025-04-21T10:15:57.969330Z",
     "shell.execute_reply.started": "2025-04-21T10:15:49.000012Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics -q\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe412d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:19:25.786747Z",
     "iopub.status.busy": "2025-04-21T10:19:25.786050Z",
     "iopub.status.idle": "2025-04-21T10:19:25.791151Z",
     "shell.execute_reply": "2025-04-21T10:19:25.790318Z",
     "shell.execute_reply.started": "2025-04-21T10:19:25.786717Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the class labels to verify the correct class ID for 'Car'\n",
    "print(\"Class labels:\", result.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9372ae2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a814b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T07:34:14.650080Z",
     "iopub.status.busy": "2025-04-21T07:34:14.649322Z",
     "iopub.status.idle": "2025-04-21T07:34:15.887542Z",
     "shell.execute_reply": "2025-04-21T07:34:15.886719Z",
     "shell.execute_reply.started": "2025-04-21T07:34:14.650027Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 7\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# while i<17:\n",
    "# Load YOLOv11 model\n",
    "# print(i)\n",
    "model_path = \"/kaggle/input/yolo11_trained/pytorch/default/1/yolo11m.pt\"\n",
    "model = YOLO(model_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = \"/kaggle/input/kitti-dataset/data_object_image_2/testing/image_2/000007.png\"\n",
    "original_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "input_tensor = preprocess(original_image).unsqueeze(0).to(device)\n",
    "input_tensor.requires_grad_()\n",
    "\n",
    "# Get class names and find 'Car' index\n",
    "class_names = model.names\n",
    "car_class_index = [k for k, v in class_names.items() if v.lower() == \"car\"]\n",
    "if not car_class_index:\n",
    "    raise ValueError(\"Car class not found.\")\n",
    "car_class_index = car_class_index[0]\n",
    "\n",
    "# Hook Grad-CAM\n",
    "activations = None\n",
    "gradients = None\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output[0]\n",
    "# Use full backward hook (for modern PyTorch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target_layer = model.model.model[16] # Should be a deep convolutional layer\n",
    "#i+=1\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "# Forward pass through raw model\n",
    "output = model.model(input_tensor)[0]  # shape: (1, N, 5 + num_classes)\n",
    "output = output[0]  # Remove batch dim\n",
    "\n",
    "# Apply sigmoid to confidence and softmax to class scores\n",
    "obj_conf = output[:, 4]\n",
    "class_probs = output[:, 5:]\n",
    "# objectness × class score, which gives high precision Grad-CAM\n",
    "car_scores = obj_conf * class_probs[:, car_class_index]\n",
    "\n",
    "# Get top car prediction index\n",
    "if car_scores.max() == 0:\n",
    "    raise ValueError(\"No car detected in the raw output.\")\n",
    "\n",
    "top_idx = torch.argmax(car_scores)\n",
    "score = car_scores[top_idx]\n",
    "# score = car_scores.mean()####################################################\n",
    "\n",
    "\n",
    "# Backward from the top car score\n",
    "model.model.zero_grad()\n",
    "score.backward(retain_graph=True)\n",
    "\n",
    "# Compute Grad-CAM\n",
    "weights = gradients.mean(dim=(2, 3), keepdim=True)\n",
    "cam = (weights * activations).sum(dim=1, keepdim=True)\n",
    "cam = F.relu(cam)\n",
    "\n",
    "# Normalize and resize CAM\n",
    "cam = cam.squeeze().detach().cpu().numpy()\n",
    "cam = cv2.resize(cam, (640, 640))\n",
    "cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-6)\n",
    "\n",
    "# Create overlay\n",
    "original_np = np.array(original_image.resize((640, 640))) / 255.0\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "overlay = heatmap + original_np\n",
    "overlay = overlay / np.max(overlay)\n",
    "\n",
    "# Display\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(original_np)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.imshow(cam, cmap=\"jet\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Overlay\")\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ad3c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Version 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b29df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:20:41.567069Z",
     "iopub.status.busy": "2025-04-21T10:20:41.566480Z",
     "iopub.status.idle": "2025-04-21T10:20:43.010177Z",
     "shell.execute_reply": "2025-04-21T10:20:43.009373Z",
     "shell.execute_reply.started": "2025-04-21T10:20:41.567041Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 7\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load YOLOv11 model\n",
    "model_path = \"/kaggle/input/yolov11m-pt/yolo11m.pt\"\n",
    "model = YOLO(model_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = \"/kaggle/input/kitti-dataset/data_object_image_2/testing/image_2/000002.png\"\n",
    "original_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "input_tensor = preprocess(original_image).unsqueeze(0).to(device)\n",
    "input_tensor.requires_grad_()\n",
    "\n",
    "# Get class names and find 'Car' index\n",
    "class_names = model.names\n",
    "car_class_index = [k for k, v in class_names.items() if v.lower() == \"car\"]\n",
    "if not car_class_index:\n",
    "    raise ValueError(\"Car class not found.\")\n",
    "car_class_index = car_class_index[0]\n",
    "\n",
    "# Hook Grad-CAM\n",
    "activations = None\n",
    "gradients = None\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output[0]\n",
    "\n",
    "# Register hooks\n",
    "target_layer = model.model.model[16]  # Should be a deep conv layer\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "# Forward pass through raw model\n",
    "output = model.model(input_tensor)[0]  # shape: (1, N, 5 + num_classes)\n",
    "output = output[0]  # Remove batch dim\n",
    "\n",
    "# Compute car class scores\n",
    "obj_conf = output[:, 4]\n",
    "class_probs = output[:, 5:]\n",
    "car_scores = obj_conf * class_probs[:, car_class_index]\n",
    "\n",
    "# Select top car\n",
    "if car_scores.max() == 0:\n",
    "    raise ValueError(\"No car detected in raw output.\")\n",
    "    \n",
    "top_idx = torch.argmax(car_scores)\n",
    "score = car_scores[top_idx]\n",
    "# Get top-k car detections\n",
    "# top_k = 5  # You can tune this number\n",
    "# topk_scores, topk_indices = torch.topk(car_scores, k=top_k)\n",
    "\n",
    "# # Filter zero-score predictions\n",
    "# non_zero = topk_scores > 0\n",
    "# if non_zero.sum() == 0:\n",
    "#     raise ValueError(\"No high-scoring car predictions.\")\n",
    "# filtered_scores = topk_scores[non_zero]\n",
    "\n",
    "# # Take mean score for Grad-CAM\n",
    "# score = filtered_scores.mean()\n",
    "\n",
    "\n",
    "\n",
    "# Backward pass for Grad-CAM\n",
    "model.model.zero_grad()\n",
    "score.backward(retain_graph=True)\n",
    "\n",
    "# Grad-CAM computation\n",
    "weights = gradients.mean(dim=(2, 3), keepdim=True)\n",
    "cam = (weights * activations).sum(dim=1, keepdim=True)\n",
    "cam = F.relu(cam)\n",
    "\n",
    "# Normalize CAM using Clipping Percentiles\n",
    "cam = cam.squeeze().detach().cpu().numpy()\n",
    "cam = cv2.resize(cam, (640, 640))\n",
    "\n",
    "# Compute 1st and 99th percentiles\n",
    "p1, p99 = np.percentile(cam, 1), np.percentile(cam, 99)\n",
    "\n",
    "# Clip and rescale to [0, 1]\n",
    "cam = np.clip(cam, p1, p99)\n",
    "cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-6)\n",
    "\n",
    "# Create heatmap overlay\n",
    "original_np = np.array(original_image.resize((640, 640))) / 255.0\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "overlay = heatmap + original_np\n",
    "overlay = overlay / np.max(overlay)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(original_np)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.imshow(cam, cmap=\"jet\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Overlay\")\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show detection result\n",
    "results[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25018b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T10:23:01.499311Z",
     "iopub.status.busy": "2025-04-21T10:23:01.498481Z",
     "iopub.status.idle": "2025-04-21T10:23:02.995243Z",
     "shell.execute_reply": "2025-04-21T10:23:02.994472Z",
     "shell.execute_reply.started": "2025-04-21T10:23:01.499284Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 7\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load YOLOv11 model\n",
    "model_path = \"/kaggle/input/yolov11m-pt/yolo11m.pt\"\n",
    "model = YOLO(model_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = \"/kaggle/input/kitti-dataset/data_object_image_2/testing/image_2/000002.png\"\n",
    "original_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "input_tensor = preprocess(original_image).unsqueeze(0).to(device)\n",
    "input_tensor.requires_grad_()\n",
    "\n",
    "# Get class names and find 'Car' index\n",
    "class_names = model.names\n",
    "car_class_index = [k for k, v in class_names.items() if v.lower() == \"car\"]\n",
    "if not car_class_index:\n",
    "    raise ValueError(\"Car class not found.\")\n",
    "car_class_index = car_class_index[0]\n",
    "\n",
    "# Hook Grad-CAM\n",
    "activations = None\n",
    "gradients = None\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output[0]\n",
    "\n",
    "# Register hooks\n",
    "target_layer = model.model.model[16]  # Should be a deep conv layer\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "# Forward pass through raw model\n",
    "output = model.model(input_tensor)[0]  # shape: (1, N, 5 + num_classes)\n",
    "output = output[0]  # Remove batch dim\n",
    "\n",
    "# Compute car class scores\n",
    "obj_conf = output[:, 4]\n",
    "class_probs = output[:, 5:]\n",
    "car_scores = obj_conf * class_probs[:, car_class_index]\n",
    "\n",
    "# Select top car\n",
    "if car_scores.max() == 0:\n",
    "    raise ValueError(\"No car detected in raw output.\")\n",
    "    \n",
    "# top_idx = torch.argmax(car_scores)\n",
    "# score = car_scores[top_idx]\n",
    "# Get top-k car detections\n",
    "top_k = 5  # You can tune this number\n",
    "topk_scores, topk_indices = torch.topk(car_scores, k=top_k)\n",
    "\n",
    "# Filter zero-score predictions\n",
    "non_zero = topk_scores > 0\n",
    "if non_zero.sum() == 0:\n",
    "    raise ValueError(\"No high-scoring car predictions.\")\n",
    "filtered_scores = topk_scores[non_zero]\n",
    "\n",
    "# Take mean score for Grad-CAM\n",
    "score = filtered_scores.mean()\n",
    "\n",
    "\n",
    "\n",
    "# Backward pass for Grad-CAM\n",
    "model.model.zero_grad()\n",
    "score.backward(retain_graph=True)\n",
    "\n",
    "# Grad-CAM computation\n",
    "weights = gradients.mean(dim=(2, 3), keepdim=True)\n",
    "cam = (weights * activations).sum(dim=1, keepdim=True)\n",
    "cam = F.relu(cam)\n",
    "\n",
    "# Normalize CAM using Clipping Percentiles\n",
    "cam = cam.squeeze().detach().cpu().numpy()\n",
    "cam = cv2.resize(cam, (640, 640))\n",
    "\n",
    "# Compute 1st and 99th percentiles\n",
    "p1, p99 = np.percentile(cam, 1), np.percentile(cam, 99)\n",
    "\n",
    "# Clip and rescale to [0, 1]\n",
    "cam = np.clip(cam, p1, p99)\n",
    "cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-6)\n",
    "\n",
    "# Create heatmap overlay\n",
    "original_np = np.array(original_image.resize((640, 640))) / 255.0\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "overlay = heatmap + original_np\n",
    "overlay = overlay / np.max(overlay)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(original_np)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.imshow(cam, cmap=\"jet\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Overlay\")\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show detection result\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2dc40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T07:40:55.324224Z",
     "iopub.status.busy": "2025-04-21T07:40:55.323869Z",
     "iopub.status.idle": "2025-04-21T07:40:55.329878Z",
     "shell.execute_reply": "2025-04-21T07:40:55.328936Z",
     "shell.execute_reply.started": "2025-04-21T07:40:55.324200Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7231830",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c6b59",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95912da6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ Step 1: Setup – Imports & Model Loading\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d382745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:22:41.157640Z",
     "iopub.status.busy": "2025-04-21T11:22:41.157068Z",
     "iopub.status.idle": "2025-04-21T11:22:41.192374Z",
     "shell.execute_reply": "2025-04-21T11:22:41.191460Z",
     "shell.execute_reply.started": "2025-04-21T11:22:41.157610Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ Step 2: Prepare a Test Image\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"/kaggle/input/kitti-dataset/data_object_image_2/testing/image_2/000002.png\"\n",
    "raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((640, 640)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "input_image = transform(raw_image).unsqueeze(0)  # Shape: [1, 3, H, W]\n",
    "input_image.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccea34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:23:05.631221Z",
     "iopub.status.busy": "2025-04-21T11:23:05.630655Z",
     "iopub.status.idle": "2025-04-21T11:23:05.636661Z",
     "shell.execute_reply": "2025-04-21T11:23:05.635786Z",
     "shell.execute_reply.started": "2025-04-21T11:23:05.631191Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23991800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:44:28.248838Z",
     "iopub.status.busy": "2025-04-21T11:44:28.248509Z",
     "iopub.status.idle": "2025-04-21T11:44:28.278961Z",
     "shell.execute_reply": "2025-04-21T11:44:28.278187Z",
     "shell.execute_reply.started": "2025-04-21T11:44:28.248815Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d4ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:41:39.148496Z",
     "iopub.status.busy": "2025-04-21T11:41:39.148144Z",
     "iopub.status.idle": "2025-04-21T11:41:39.153159Z",
     "shell.execute_reply": "2025-04-21T11:41:39.152292Z",
     "shell.execute_reply.started": "2025-04-21T11:41:39.148469Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_for_car_class(input_tensor, target_box_idx):\n",
    "    \"\"\"\n",
    "    Returns the confidence score for class 'Car' (index 2) for a specific detection box.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_tensor)[0]  # Shape: [num_boxes, 5 + num_classes]\n",
    "\n",
    "    car_class_index = 2  # Focus only on 'Car'\n",
    "    return predictions[target_box_idx,  5+car_class_index].unsqueeze(0)  # Shape: [1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ced73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:41:39.377861Z",
     "iopub.status.busy": "2025-04-21T11:41:39.377140Z",
     "iopub.status.idle": "2025-04-21T11:41:39.553073Z",
     "shell.execute_reply": "2025-04-21T11:41:39.552379Z",
     "shell.execute_reply.started": "2025-04-21T11:41:39.377830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Example tensor: shape [3, H, W] or [1, 3, H, W]\n",
    "image_tensor = input_image.squeeze(0)  # if shape is [1, 3, H, W]\n",
    "\n",
    "# Convert from [C, H, W] to [H, W, C] and detach from graph\n",
    "image_np = image_tensor.permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "# Optional: if image values are in [0,1], display directly. If in [0,255], cast to uint8\n",
    "plt.imshow(image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4b460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:41:39.562635Z",
     "iopub.status.busy": "2025-04-21T11:41:39.561973Z",
     "iopub.status.idle": "2025-04-21T11:41:40.994561Z",
     "shell.execute_reply": "2025-04-21T11:41:40.993185Z",
     "shell.execute_reply.started": "2025-04-21T11:41:39.562609Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set your target class and detection box index manually for now\n",
    "target_box_index = 0  # e.g., first detection\n",
    "target_class_index = 2  # e.g., 'car'\n",
    "\n",
    "# Initialize Integrated Gradients\n",
    "# ig = IntegratedGradients(lambda x: forward_for_target_class(x, target_box_index, target_class_index))\n",
    "ig = IntegratedGradients(lambda x: forward_for_car_class(x, target_box_index))\n",
    "# input_image.size()\n",
    "# Choose a baseline (black image)\n",
    "# baseline = torch.zeros_like(input_image)\n",
    "baseline = torch.zeros_like(input_image)\n",
    "# print(baseline)\n",
    "# plt.imshow(input_image)\n",
    "# baseline.size()\n",
    "# print(\"Hello\")\n",
    "# Compute attributions\n",
    "# attributions = ig.attribute(input_image, baseline, target=0, n_steps=50)\n",
    "attributions = ig.attribute(input_image, baseline, target=0, n_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eaced4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T11:39:32.577962Z",
     "iopub.status.busy": "2025-04-21T11:39:32.577153Z",
     "iopub.status.idle": "2025-04-21T11:39:32.583216Z",
     "shell.execute_reply": "2025-04-21T11:39:32.582319Z",
     "shell.execute_reply.started": "2025-04-21T11:39:32.577935Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ba2fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 976194,
     "sourceId": 1650695,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3673013,
     "sourceId": 6374376,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7031451,
     "sourceId": 11252062,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30528,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.800224,
   "end_time": "2025-04-21T11:45:35.868668",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-21T11:45:27.068444",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
